<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>04_the_reals (MathJax Version)</title>
  <style>
    /* Styles will be inserted here */
  </style>
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
</head>
<body>

<a href="#main">Skip to main content</a>

<header>
  <h1>04_the_reals (MathJax Version)</h1>
</header>

<nav aria-label="Page Navigation">
  <ul>
    <li><a href="../">Back to Generated Index</a></li>
            <li><a href="../mathml/04_the_reals-mathml.html">Switch to MathML Version</a></li>
      </ul>
</nav>

<main id="main">
<h2 id="motivation-for-the-reals">Motivation for the reals</h2>
<p>Why do we need the real numbers in the first place? Well, we
introduce new sets of numbers when there are equations that we cannot
solve using our current number system. For example, the equation <span
class="math inline">\(x+2=0\)</span> is not solvable in <span
class="math inline">\(\mathbb N\)</span>, so we constructed <span
class="math inline">\(\mathbb Z\)</span>. Then we could not solve
equations like <span class="math inline">\(2x = 3\)</span>, so we
created the rationals, <span class="math inline">\(\mathbb Q\)</span>.
Now, we cannot solve equations such as <span class="math inline">\(x^2 =
2\)</span>, so we must create a new set of numbers that contains this
solution.</p>
<h3>Proposition</h3>
<p>There does not exist a <span class="math inline">\(q \in \mathbb
Q\)</span> such that <span class="math inline">\(q^2 = 2\)</span>. Note
that in this proposition we make no assumption that <span
class="math inline">\(q^2 = 2\)</span> is solvable, or that a solution
if one exists does not lie within <span class="math inline">\(\mathbb
Q\)</span>; we simply state that confined to the realm of <span
class="math inline">\(\mathbb Q\)</span> the equation is unsolvable.</p>
<h3>Proof</h3>
<p><em>Proof 1.</em> Suppose that such a <span class="math inline">\(q
\in \mathbb Q\)</span> exists, such that <span class="math inline">\(q^2
= 2\)</span>. Without loss of generality, we will assume that <span
class="math inline">\(q&gt;0\)</span> because <span
class="math inline">\((-q)^2 = q^2\)</span>. So let <span
class="math inline">\(q\)</span> be written as <span
class="math inline">\(a/b\)</span> where <span class="math inline">\(a,
b \in \mathbb N\)</span>. Then <span class="math inline">\(a^2/b^2 =
2\)</span>, so <span class="math inline">\(a^2 = 2b^2\)</span>. If we
factorise each side as a product of primes, the exponent of the prime 2
on the left hand side must be even, but on the right hand side it must
be odd. This contradicts the unique factorisation of natural numbers. So
such a <span class="math inline">\(q\)</span> does not exist. ◻</p>
<h3>Proof</h3>
<p><em>Proof 2.</em> Suppose that there exists some <span
class="math inline">\(q \in \mathbb Q\)</span> written similarly to
above as <span class="math inline">\(a/b\)</span>. Note that for any
<span class="math inline">\(c, d \in \mathbb Z\)</span>, <span
class="math inline">\(cq + d\)</span> is of the form <span
class="math inline">\(e/b\)</span> for some integer <span
class="math inline">\(e\)</span>. Therefore, if <span
class="math inline">\(cq+d&gt;0\)</span> then <span
class="math inline">\(cq+d \geq 1/b\)</span>.</p>
<p>Now, note that <span class="math inline">\(0 &lt; (q - 1) &lt;
1\)</span>, so for a suitably large <span
class="math inline">\(n\)</span>, we have <span class="math inline">\(0
&lt; (q - 1)^n &lt; 1/b\)</span>. However, <span
class="math inline">\((q-1)^n\)</span> is of the form <span
class="math inline">\(cq+d\)</span> because <span
class="math inline">\(q^2 = 1\)</span> so we can eliminate all
exponents. This is a contradiction so such a <span
class="math inline">\(q\)</span> does not exist. ◻</p>
<p>We can see from the proofs above that <span
class="math inline">\(\mathbb Q\)</span> has a ‘gap’ at <span
class="math inline">\(\sqrt 2\)</span>. How can we express this fact
without mentioning <span class="math inline">\(\mathbb R\)</span>? We
can’t just say plainly that <span class="math inline">\(\sqrt 2 \notin
\mathbb Q\)</span> because as far as we know from <span
class="math inline">\(\mathbb Q\)</span>, there is no reason to assume
that such a number called <span class="math inline">\(\sqrt 2\)</span>
even exists! We need to find a way to express the concept of <span
class="math inline">\(\sqrt 2\)</span> in the language of <span
class="math inline">\(\mathbb Q\)</span>. One way to do this is by
creating sone set <span class="math inline">\(S = \{ q \in \mathbb Q:
q^2 &lt; 2 \}\)</span>. Then we can write down some upper bounds for
this set. For example, 2 is a trivial upper bound, as is <span
class="math inline">\(1.5\)</span>, and as is <span
class="math inline">\(1.42\)</span>. In fact, we can continue making
smaller and smaller upper bounds. We can see therefore that there exists
no least upper bound in <span class="math inline">\(\mathbb
Q\)</span>.</p>
<h2 id="axioms-of-the-reals">Axioms of the reals</h2>
<p>We define the reals as follows: the reals are a set written <span
class="math inline">\(\mathbb R\)</span> with elements 0 and 1 with
<span class="math inline">\(0 \neq 1\)</span>; with operations <span
class="math inline">\(+\)</span> and <span
class="math inline">\(\cdot\)</span>; and an ordering <span
class="math inline">\(&lt;\)</span>; such that:</p>
<ol>
<li><p><span class="math inline">\(+\)</span> is commutative,
associative, has identity 0, and there are inverses for all
elements;</p></li>
<li><p><span class="math inline">\(\cdot\)</span> is commutative,
associative, has identity 1, and there are inverses for all nonzero
elements;</p></li>
<li><p><span class="math inline">\(\cdot\)</span> is distributive over
<span class="math inline">\(+\)</span>;</p></li>
<li><p>for all <span class="math inline">\(a\)</span> and <span
class="math inline">\(b\)</span> in <span class="math inline">\(\mathbb
R\)</span>, exactly one of <span class="math inline">\(a&lt;b\)</span>,
<span class="math inline">\(a=b\)</span> and <span
class="math inline">\(a&gt;b\)</span> are true, and that <span
class="math inline">\(a&lt;b\)</span> and <span
class="math inline">\(b&lt;c\)</span> implies <span
class="math inline">\(a&lt;c\)</span>;</p></li>
<li><p>for all <span class="math inline">\(a, b, c \in \mathbb
R\)</span>, <span class="math inline">\(a&lt;b\)</span> implies <span
class="math inline">\(a + c &lt; b + c\)</span>, and <span
class="math inline">\(a&lt;b\)</span> implies <span
class="math inline">\(ac &lt; bc\)</span> when <span
class="math inline">\(c &gt; 0\)</span>; and</p></li>
<li><p>for any set <span class="math inline">\(S\)</span> of reals that
is non-empty and bounded above, <span class="math inline">\(S\)</span>
has a least upper bound.</p></li>
</ol>
<p>There are some notable immediate remarks about the definitions of the
reals.</p>
<ul>
<li><p>We can contain the rationals inside the reals: <span
class="math inline">\(\mathbb Q \subset \mathbb R\)</span></p></li>
<li><p>The least upper bound axiom is false in <span
class="math inline">\(\mathbb Q\)</span>, which is why it’s so important
in <span class="math inline">\(\mathbb R\)</span>.</p></li>
<li><p>Why did we specify ‘non-empty’ and ‘bounded above’ in the least
upper bound axiom? Of course, if a set is not bounded above, then it has
no upper bound, so clearly it can have no least upper bound. If a set is
empty, then every real is an upper bound for this set, and as there is
no least real number, there is no least upper bound.</p></li>
<li><p>It is possible to construct <span class="math inline">\(\mathbb
R\)</span> out of <span class="math inline">\(\mathbb Q\)</span>, and
check that the above axioms hold. However, this is a rare example where
the construction of <span class="math inline">\(\mathbb R\)</span> is
complicated and irrelevant, so it is not covered here.</p></li>
</ul>
<p>The reals do not contain infinitely big or infinitesimally small
elements.</p>
<h3>Proposition</h3>
<p><span class="math inline">\(\mathbb N\)</span> is not bounded above
in <span class="math inline">\(\mathbb R\)</span>.</p>
<h3>Proof</h3>
<p>If there were some upper bound <span class="math inline">\(c = \sup
\mathbb N\)</span>, then <span class="math inline">\(c-1\)</span> is
clearly not an upper bound for <span class="math inline">\(\mathbb
N\)</span>. So there exists some natural number <span
class="math inline">\(n\)</span> such that <span class="math inline">\(n
&gt; c-1\)</span>. But then clearly <span class="math inline">\(n+1 \in
\mathbb N &gt; c\)</span> contradicting the existence of this upper
bound. ◻</p>
<h3>Corollary</h3>
<p>For each <span class="math inline">\(t \in \mathbb R &gt; 0\)</span>,
<span class="math inline">\(\exists n \in \mathbb N\)</span> such that
<span class="math inline">\(\frac{1}{n} &lt; t\)</span>.</p>
<h3>Proof</h3>
<p>We have some <span class="math inline">\(n \in \mathbb N\)</span>
with <span class="math inline">\(n &gt; \frac{1}{t}\)</span> by the
above proposition. So <span class="math inline">\(\frac{1}{n} &lt;
t\)</span>. ◻</p>
<h2 id="examples-of-sets-and-least-upper-bounds">Examples of sets and
least upper bounds</h2>
<p>Note that a common way to write ‘least upper bound’ is the word
supremum, denoted <span class="math inline">\(\sup S\)</span>.</p>
<ol>
<li><p>Let <span class="math inline">\(S = \{ x \in \mathbb R: 0 \leq x
\leq 1 \} = [0, 1]\)</span>. The least upper bound of <span
class="math inline">\(S\)</span> is 1, because:</p>
<ul>
<li><p>1 is an upper bound for <span class="math inline">\(S\)</span>;
<span class="math inline">\(\forall x \in S, x\leq1\)</span>;
and</p></li>
<li><p>Every upper bound <span class="math inline">\(y\)</span> must
have <span class="math inline">\(y \geq 1\)</span> because <span
class="math inline">\(1 \in S\)</span>.</p></li>
</ul></li>
<li><p>Let <span class="math inline">\(S = \{ x \in \mathbb R: 0 &lt; x
&lt; 1 \} = (0, 1)\)</span>. <span class="math inline">\(\sup S =
1\)</span> because:</p>
<ul>
<li><p>1 is an upper bound for <span class="math inline">\(S\)</span>;
<span class="math inline">\(\forall x \in S, x \leq 1\)</span>;
and</p></li>
<li><p>No upper bound <span class="math inline">\(c\)</span> has <span
class="math inline">\(c&lt;1\)</span>. Indeed, certainly <span
class="math inline">\(c&gt;0\)</span> (<span class="math inline">\(c
&gt; \frac{1}{2}\)</span> since <span class="math inline">\(\frac{1}{2}
\in S\)</span>). So if <span class="math inline">\(c&lt;1\)</span>, then
<span class="math inline">\(0&lt;c&lt;1\)</span>, so the number <span
class="math inline">\(\frac{1+c}{2} \in S\)</span> and is larger than
<span class="math inline">\(c\)</span>, so it is not an upper
bound.</p></li>
</ul></li>
<li><p>Let <span class="math inline">\(S = \qty{ 1 - \frac{1}{n}: n \in
\mathbb N }\)</span>. <span class="math inline">\(\sup S = 1\)</span>
because:</p>
<ul>
<li><p>1 is clearly an upper bound.</p></li>
<li><p>Let us suppose <span class="math inline">\(c &lt; 1\)</span> is
an upper bound. Then <span class="math inline">\(\forall n \in \mathbb
N, 1 - \frac{1}{n} &lt; c\)</span> so <span class="math inline">\(1 - c
&lt; \frac{1}{n}\)</span>. From the corollary of the Axiom of Archimedes
above, this is a contradiction.</p></li>
</ul></li>
</ol>
<h3>Remark</h3>
<p>If <span class="math inline">\(S\)</span> has a greatest element,
then this element is the supremum of the set: <span
class="math inline">\(\sup S \in S\)</span>. But if <span
class="math inline">\(S\)</span> does not have a greatest element, then
<span class="math inline">\(\sup S \notin S\)</span>. Also, we do not
need any kind of ‘greatest lower bound’ axiom—if <span
class="math inline">\(S\)</span> is a non-empty, bounded below set of
reals, then the set <span class="math inline">\(\{ -x: x \in S
\}\)</span> is non-empty and bounded above, and so has a least upper
bound, so <span class="math inline">\(S\)</span> has a greatest lower
bound equivalent to its additive inverse. This is commonly called the
‘infimum’, or <span class="math inline">\(\inf S\)</span>.</p>
<h3>Theorem</h3>
<p><span class="math inline">\(\exists x \in \mathbb R\)</span> with
<span class="math inline">\(x^2 = 2\)</span>.</p>
<h3>Proof</h3>
<p>Let <span class="math inline">\(S\)</span> be the set of all real
numbers such that <span class="math inline">\(x^2 &lt; 2\)</span>. Of
course, it is non-empty (try <span class="math inline">\(x=0\)</span>)
and bounded above (try <span class="math inline">\(x=2\)</span>). So let
<span class="math inline">\(c = \sup S\)</span>; we want to show that
<span class="math inline">\(c^2 = 2\)</span>. We prove this by
eliminating all alternatives; clearly either <span
class="math inline">\(c^2 &lt; 2\)</span>, <span
class="math inline">\(c^2 = 2\)</span> or <span
class="math inline">\(c^2 &gt; 2\)</span>.</p>
<ul>
<li><p>(<span class="math inline">\(c^2 &lt; 2\)</span>) We want to
prove that <span class="math inline">\((c+t)^2 &lt; 2\)</span> for some
small <span class="math inline">\(t\)</span>. For <span
class="math inline">\(0&lt;t&lt;1\)</span>, we have <span
class="math inline">\((c+t)^2 = c^2 + 2ct + t^2 \leq c^2 + 5t\)</span>,
since <span class="math inline">\(c\)</span> is at most 2, and <span
class="math inline">\(t^2\)</span> is at most <span
class="math inline">\(t\)</span>. So this value is less than 2 for some
suitably small <span class="math inline">\(t\)</span>, contradicting the
least upper bound—we have just shown that <span
class="math inline">\((c+t) \in S\)</span>.</p></li>
<li><p>(<span class="math inline">\(c^2 &gt; 2\)</span>) We want to
prove that <span class="math inline">\((c-t)^2 &gt; 2\)</span> for some
small <span class="math inline">\(t\)</span>. For <span
class="math inline">\(0&lt;t&lt;1\)</span>, we have <span
class="math inline">\((c-t)^2 = c^2 - 2ct + t^2 \geq c^2 - 4t\)</span>,
since <span class="math inline">\(c\)</span> is at most 2, and <span
class="math inline">\(t^2\)</span> is at least zero. So this value is
greater than 2 for some suitably small <span
class="math inline">\(t\)</span>, contradicting the least upper bound—we
have just created a lower upper bound.</p></li>
</ul>
<p>So <span class="math inline">\(c^2 = 2\)</span>. ◻</p>
<p>This same kind of proof works for a lot of real values, for example
<span class="math inline">\(\sqrt[n]{x}\)</span> for <span
class="math inline">\(n \in \mathbb N\)</span>, <span
class="math inline">\(x\in \mathbb R, x &lt; 0\)</span>. Reals that are
not rational are called irrational. This is a negative statement
however, so it is better in proofs to suppose that something is
rational, and then show a contradiction.</p>
<p>Also, the rationals are ‘dense’; for any <span
class="math inline">\(a, b \in \mathbb R\)</span>, there is another
rational between them. We may assume without loss of generality that
they are both non-negative and that <span
class="math inline">\(a&lt;b\)</span>. Then pick some <span
class="math inline">\(n \in \mathbb N\)</span> with <span
class="math inline">\(\frac{1}{n} &lt; b-a\)</span>. Among the list
<span class="math inline">\(\frac{0}{n}, \frac{1}{n}, \frac{2}{n},
\dots\)</span>, there is a final one that is less than or equal to <span
class="math inline">\(a\)</span>, which we will denote <span
class="math inline">\(\frac{q}{n}\)</span> (otherwise <span
class="math inline">\(a\)</span> is an upper bound to this list,
contradicting the axiom of Archimedes). So <span class="math inline">\(a
&lt; \frac{q + 1}{n} &lt; b\)</span> as required.</p>
<p>The irrationals are also dense; for any reals <span
class="math inline">\(a\)</span> and <span
class="math inline">\(b\)</span> with the same conditions above, these
exists some irrational <span class="math inline">\(c\)</span> with <span
class="math inline">\(a&lt;c&lt;b\)</span>. We know that there exists a
rational <span class="math inline">\(c\)</span> with <span
class="math inline">\(a\sqrt{2} &lt; c &lt; b\sqrt{2}\)</span>, so <span
class="math inline">\(a &lt; \frac{c}{\sqrt{2}} &lt; b\)</span>.</p>
<h2 id="sequences-and-limits">Sequences and limits</h2>
<p>How can we ascribe meaning to expressions like this? <span
class="math display">\[1 + \frac{1}{2} + \frac{1}{4} + \frac{1}{8} +
\dots\]</span> Certainly, we have a concept of addition, and we can keep
adding as many terms as we like, but there is no implicit definition of
an infinite sum from the aforementioned axioms.</p>
<p>A definition that makes sense would involve partial sums <span
class="math inline">\(x_n\)</span> of this infinite series. However, we
could not just say that the partial sums get progressively closer to a
value, because then trivially something like <span
class="math inline">\(\frac{1}{2}, \frac{2}{3}, \frac{3}{4},
\frac{4}{5}, \dots\)</span> tends to 107, even though they’re clearly
getting closer.</p>
<p>A more accurate definition would be to state that we can get
arbitrarily close (within some given <span
class="math inline">\(\varepsilon\)</span>) to a ‘limit value’ <span
class="math inline">\(c\)</span> by taking some amount of terms <span
class="math inline">\(n\)</span> of this series: <span
class="math inline">\(c - \varepsilon &lt; x_n &lt; c +
\varepsilon\)</span>. But this is still wrong: the sequence <span
class="math inline">\(\frac{1}{2}, 10, \frac{2}{3}, 10, \frac{3}{4}, 10,
\frac{4}{5}, 10, \dots\)</span> could then tend to 1 even though every
other term is 10.</p>
<p>The best definition would state that the sequence of partial sums
would <em>stay</em> within <span
class="math inline">\(\varepsilon\)</span> of <span
class="math inline">\(c\)</span> for all <span
class="math inline">\(x_k\)</span> where <span class="math inline">\(k
\geq n\)</span> for some <span class="math inline">\(n \in \mathbb
N\)</span>. In less formal words, for any <span
class="math inline">\(\varepsilon &gt; 0\)</span>, <span
class="math inline">\(x_n\)</span> will eventually stay within <span
class="math inline">\(\varepsilon\)</span> of <span
class="math inline">\(c\)</span>. Equivalently, <span
class="math inline">\(\forall \varepsilon &gt; 0, \exists N \in \mathbb
N\)</span> such that <span class="math inline">\(\forall n &gt;
N\)</span> we have <span class="math inline">\(\abs{x_n - c} &lt;
\varepsilon\)</span>.</p>
<ol>
<li><p>Consider the sequence <span class="math inline">\(\frac{1}{2},\;
\frac{1}{2} + \frac{1}{4},\; \frac{1}{2} + \frac{1}{4} + \frac{1}{8},
\dots\)</span>. This is <span class="math inline">\(x_1, x_2, x_3,
\dots\)</span> where <span class="math inline">\(x_n = 1 -
\frac{1}{2^n}\)</span> (inductively on <span
class="math inline">\(n\)</span>). We want to show that <span
class="math inline">\(x_n\)</span> tends to 1. Given some <span
class="math inline">\(\varepsilon &gt; 0\)</span>, we choose some <span
class="math inline">\(N \in \mathbb N\)</span> with <span
class="math inline">\(N &gt; \frac{1}{\varepsilon}\)</span>. Then, for
every <span class="math inline">\(n \geq N\)</span>, <span
class="math inline">\(\abs{x_n - 1} = \frac{1}{2^n} \leq \frac{1}{n}
\leq \frac{1}{N} &lt; \varepsilon\)</span>.</p></li>
<li><p>Consider the constant sequence <span class="math inline">\(c, c,
c, c, \dots\)</span>. We want to show that <span
class="math inline">\(x_n \to c\)</span>. Given some <span
class="math inline">\(\varepsilon &gt; 0\)</span>, we have <span
class="math inline">\(\abs*{x_n - c} &lt; \varepsilon\)</span> for all
<span class="math inline">\(n\)</span>; <span
class="math inline">\(N=1\)</span> is the time after which the sequence
stays within <span class="math inline">\(\varepsilon\)</span> of <span
class="math inline">\(c\)</span>.</p></li>
<li><p>Consider now <span class="math inline">\(x_n = (-1)^n\)</span>,
i.e. <span class="math inline">\(-1, 1, -1, 1, \dots\)</span>. We want
to show that this does not tend to a limit. Suppose <span
class="math inline">\(x_n \to c\)</span> as <span
class="math inline">\(n \to \infty\)</span>. We may choose some <span
class="math inline">\(\varepsilon\)</span> that acts as a
counterexample—for example, <span class="math inline">\(\varepsilon =
1\)</span>. So <span class="math inline">\(\exists N \in \mathbb
N\)</span> such that <span class="math inline">\(\forall n \geq
n\)</span> we have <span class="math inline">\(\abs{x_n - c} &lt;
1\)</span>. In particular, <span class="math inline">\(\abs{1 - c} &lt;
1\)</span> and <span class="math inline">\(\abs{-1 - c} &lt; 1\)</span>
so <span class="math inline">\(\abs{1 - (-1)} &lt; 2\)</span>, by the
triangle inequality. This is a contradiction.</p></li>
<li><p>The sequence <span class="math inline">\(x_n\)</span> given by
<span class="math display">\[x_n = \begin{cases}
                  \frac{1}{n} &amp; n \text{ odd}  \\
                  0           &amp; n \text{ even}
              \end{cases}\]</span> should tend to zero. Given some <span
class="math inline">\(\varepsilon &gt; 0\)</span>, we will choose <span
class="math inline">\(N \in \mathbb N\)</span> with <span
class="math inline">\(\frac{1}{N} &lt; \varepsilon\)</span>. Then for
all <span class="math inline">\(n \geq N\)</span>, either <span
class="math inline">\(x_n = \frac{1}{n}\)</span> or 0. In either case,
<span class="math inline">\(\abs{x_n - 0} \leq \frac{1}{n} \leq
\frac{1}{N} &lt; \varepsilon\)</span>.</p></li>
</ol>
<p>We can denote the entirety of a sequence <span
class="math inline">\(x_1, x_2, \dots\)</span> as <span
class="math display">\[(x_n) \quad \text{or} \quad
(x_n)_{n=1}^\infty\]</span> For example, <span
class="math inline">\(\left( (-1)^n \right)_{n=1}^{\infty}\)</span> is
divergent. This isn’t saying that it goes to infinity, just that it
doesn’t converge. Note also that if <span class="math inline">\(x_n \to
c\)</span> and <span class="math inline">\(x_n \to d\)</span>, then
<span class="math inline">\(c=d\)</span>. Suppose that <span
class="math inline">\(c \neq d\)</span>. Then pick <span
class="math inline">\(\varepsilon = \frac{\abs{c-d}}{2}\)</span>. Then
<span class="math inline">\(\exists N \in \mathbb N\)</span> with <span
class="math inline">\(\abs{x_n - c} &lt; \varepsilon\)</span>, and <span
class="math inline">\(\exists M \in \mathbb N\)</span> with <span
class="math inline">\(\abs{x_n - d} &lt; \varepsilon\)</span>. After the
point <span class="math inline">\(\max(N, M)\)</span>, the points must
be within <span class="math inline">\(\varepsilon\)</span> of both <span
class="math inline">\(c\)</span> and <span
class="math inline">\(d\)</span>, but as <span
class="math inline">\(c\)</span> and <span
class="math inline">\(d\)</span> are <span
class="math inline">\(2\varepsilon\)</span> apart this is a
contradiction (by the triangle inequality).</p>
<h2 id="series">Series</h2>
<p>A sequence given in the form <span class="math inline">\(x_1,\; x_1 +
x_2,\; x_1 + x_2 + x_3, \dots\)</span> is called a series. They are
often written <span class="math inline">\(\sum_{n=1}^\infty
x_n\)</span>. The <span class="math inline">\(k\)</span>th term of the
sequence, given by <span class="math inline">\(\sum_{n=1}^k
x_n\)</span>, is called the <span class="math inline">\(k\)</span>th
partial sum. If the series converges to some value <span
class="math inline">\(c\)</span>, then we can write <span
class="math inline">\(\sum_{n=1}^\infty x_n = c\)</span>. Note that we
cannot use this notation to denote the limit until we know that the
limit actually exists. This is just the same as with sequences, where we
cannot write <span class="math inline">\(\lim_{n\to\infty} x_n\)</span>
until we know that the limit exists.</p>
<p>Limits behave as we would expect. For example, if <span
class="math inline">\(x_n \leq d\)</span> for all <span
class="math inline">\(n\)</span>, and <span class="math inline">\(x_n
\to c\)</span>, then <span class="math inline">\(c \leq d\)</span>.
Suppose <span class="math inline">\(c &gt; d\)</span>. Then we will
choose <span class="math inline">\(\varepsilon = \frac{\abs{c -
d}}{2}\)</span>. Then there are no points <span
class="math inline">\(x_n\)</span> within this bound of <span
class="math inline">\(c\)</span> .</p>
<h3>Proposition</h3>
<p>If <span class="math inline">\(x_n \to c\)</span> and <span
class="math inline">\(y_n \to d\)</span>, then <span
class="math inline">\(x_n + y_n \to c + d\)</span>.</p>
<h3>Proof</h3>
<p>Given some <span class="math inline">\(\varepsilon &gt; 0\)</span>,
let <span class="math inline">\(\zeta = \frac{1}{2}\varepsilon\)</span>.
Then, after some term <span class="math inline">\(x_N\)</span>, <span
class="math inline">\(\abs{x_n - c} &lt; \zeta\)</span>, and after some
term <span class="math inline">\(y_M\)</span>, <span
class="math inline">\(\abs{y_m - d} &lt; \zeta\)</span>. So for every
<span class="math inline">\(n \geq \max(M, N)\)</span>, by the triangle
inequality, <span class="math inline">\(\abs{(x_n + y_n) - (c + d)} &lt;
2\zeta = \varepsilon\)</span> as required. ◻</p>
<p>This is commonly known as an <span
class="math inline">\(\varepsilon/2\)</span> argument. Also, if we had
instead not taken any <span class="math inline">\(\zeta\)</span> value
and just stuck with <span class="math inline">\(\varepsilon\)</span>, it
would still be a good proof because we could just have divided <span
class="math inline">\(\varepsilon\)</span> at the beginning—it’s not
expected that you completely rewrite the proof to add in this
division.</p>
<h2 id="testing-convergence-of-a-sequence">Testing convergence of a
sequence</h2>
<p>A sequence <span class="math inline">\(x_1, x_2, \dots\)</span> is
called ‘increasing’ if <span class="math inline">\(x_{n+1} \geq
x_n\)</span> for all <span class="math inline">\(n\)</span>.</p>
<h3>Theorem</h3>
<p>If <span class="math inline">\(x_1, x_2, \dots\)</span> is increasing
and bounded above, it converges to a limit.</p>
<p>This is a very important theorem that we will refer back to time and
time again.</p>
<h3>Note</h3>
<p>If we were in <span class="math inline">\(\mathbb Q\)</span>, this
would not necessarily hold. For example, consider the decimal expansion
of <span class="math inline">\(\sqrt{2}\)</span>. <span
class="math display">\[1, 1.4, 1.41, 1.414, 1.4142, \dots\]</span> They
don’t converge to a limit in <span class="math inline">\(\mathbb
Q\)</span>. So our proof will have to be more rigorous than just ‘they
have to tend to somewhere below the upper bound’; we must use a property
that <span class="math inline">\(\mathbb R\)</span> has that <span
class="math inline">\(\mathbb Q\)</span> does not have, i.e. the least
upper bound axiom.</p>
<h3>Proof</h3>
<p>Let <span class="math inline">\(c = \sup \{ x_1, x_2, \dots
\}\)</span>. We want to prove that <span class="math inline">\(x_n \to
c\)</span>. Given some <span class="math inline">\(\varepsilon &gt;
0\)</span>, there exists some <span class="math inline">\(n\)</span>
such that <span class="math inline">\(x_n &gt; c - \varepsilon\)</span>
(else, <span class="math inline">\(c - \varepsilon\)</span> would be a
smaller upper bound ). As the sequence is increasing, all <span
class="math inline">\(x_k\)</span> where <span class="math inline">\(k
&gt; n\)</span> are at least <span class="math inline">\(x_n\)</span>.
So <span class="math inline">\(\abs{x_k - c} &lt; \varepsilon\)</span>
as required. ◻</p>
<p>Of course, a decreasing sequence works in an identical way; if it is
bounded below then it converges. More compactly, a bounded monotone
sequence is convergent (where monotone means either increasing or
decreasing).</p>
<h3>Proposition</h3>
<p>The harmonic series <span class="math display">\[\sum_{n=1}^\infty
\frac 1 n\]</span> diverges; the solution to the Basel problem <span
class="math display">\[\sum_{n=1}^\infty \frac 1 {n^2}\]</span>
converges.</p>
<p>There is no closed form for the <span
class="math inline">\(n\)</span>th term of either of these sequences,
which is one reason that series are often more challenging to work with
than regular sequences.</p>
<h3>Proof</h3>
<p>Since the harmonic series is difficult to deal with, we will compare
it to a sequence that we understand easier. Therefore, we show that the
first sequence diverges using a comparison test with powers of 2, one of
the simplest series. <span class="math display">\[\begin{align*}
               &amp; 1 + \frac 1 2 + \frac 1 3 + \frac 1 4 + \frac 1 5 +
\frac 1 6 + \frac 1 7 + \frac 1 8 + \frac 1 9 +
\cdots                                                      \\
        \geq\  &amp; 1 + \frac 1 2 + \underbrace{\frac 1 4 + \frac 1
4}_{\frac 1 2} + \underbrace{\frac 1 8 + \frac 1 8 + \frac 1 8 + \frac 1
8}_{\frac 1 2} + \frac 1 {16} + \cdots
\end{align*}\]</span> By inspection, we can see that the harmonic series
is larger than the sum of an infinite amount of <span
class="math inline">\(\frac 1 2\)</span>, so surely it must diverge.
More rigorously: <span class="math display">\[\begin{align*}
        \frac 1 3 + \frac 1
4                                              &amp; \geq \frac 1
2                         \\
        \frac 1 5 + \frac 1 6 + \frac 1 7 + \frac 1
8                      &amp; \geq \frac 1 2                         \\
        \frac{1}{2^n + 1} + \frac{1}{2^n + 2} + \dots +
\frac{1}{2^{n+1}} &amp; \geq \frac{2^n}{2^{n+1}} = \frac{1}{2}
\end{align*}\]</span> So the partial sums of the series are unbounded,
so the series diverges. For the sum of reciprocals of squares, we want
to do a similar thing because again the only simple sequence we have to
work with is the powers of 2. <span
class="math display">\[\begin{align*}
               &amp; 1 + \frac 1 {2^2} + \frac 1 {3^2} + \frac 1 {4^2} +
\frac 1 {5^2} + \frac 1 {6^2} + \frac 1 {7^2} + \frac 1 {8^2} + \frac 1
{9^2} +
\cdots                                                           \\
        \leq\  &amp; 1 + \underbrace{\frac 1 {2^2} + \frac 1
{2^2}}_{\frac 2 {2^2}} + \underbrace{\frac 1 {4^2} + \frac 1 {4^2} +
\frac 1 {4^2} + \frac 1 {4^2}}_{\frac 4 {4^2}} + \frac 1 {8^2} + \frac 1
{8^2} + \cdots
\end{align*}\]</span> The bottom sequence simplifies to just the
sequence <span class="math inline">\(1 + \frac{1}{2} + \frac{1}{4} +
\frac{1}{8} + \cdots \to 2\)</span>, and the upper sequence is bounded
above by the lower sequence. More rigorously: <span
class="math display">\[\begin{align*}
        \frac{1}{2^2} +
\frac{1}{3^2}                                                &amp; \leq
\frac{2}{2^2} = \frac{1}{2}         \\
        \frac{1}{4^2} + \frac{1}{5^2} + \frac{1}{6^2} +
\frac{1}{7^2}                &amp; \leq \frac{4}{4^2} =
\frac{1}{4}         \\
        \frac{1}{(2^n)^2} + \frac{1}{(2^n + 1)^2} + \dots +
\frac{1}{(2^{n+1}-1)^2} &amp; \leq \frac{2^n}{(2^n)^2} = \frac{1}{2^n}
\end{align*}\]</span> So the partial sums are bounded, and hence the
series converges by the above theorem. ◻</p>
<p>In fact, <span class="math inline">\(\sum_{n=1}^\infty \frac{1}{n^2}
= \frac{\pi^2}{6}\)</span>. This is proved in the Linear Analysis course
in Part II.</p>
<h2 id="decimal-expansions">Decimal expansions</h2>
<p>What should <span class="math inline">\(0.a_1a_2a_3\dots\)</span>
mean (where each <span class="math inline">\(a\)</span> is a digit from
0 to 9)? It should be the limit of <span
class="math inline">\(0.a_1\)</span>, <span
class="math inline">\(0.a_1a_2\)</span>, <span
class="math inline">\(0.a_1a_2a_3\)</span> and so on. We will define it
by <span class="math display">\[0.a_1a_2a_3\dots \coloneq
\sum_{n=1}^\infty \frac{a_n}{10}\]</span> This clearly converges as the
partial sums are increasing and bounded above by 1, so infinite decimal
expansions are valid. Conversely, given some <span
class="math inline">\(x \in \mathbb R\)</span> with <span
class="math inline">\(0 &lt; x &lt; 1\)</span>, we can certainly write
it as a (potentially infinite) decimal. We will start by choosing the
greatest <span class="math inline">\(a_1\)</span> from 0 to 9 such that
<span class="math inline">\(\frac{a_1}{10} \leq x\)</span>. Thus <span
class="math inline">\(0 &lt; x - \frac{a_1}{10} &lt;
\frac{1}{10}\)</span>. Now, we can pick the greatest <span
class="math inline">\(a_2\)</span> in the set such that <span
class="math inline">\(\frac{a_1}{10} + \frac{a_2}{100} \leq x\)</span>.
Therefore, <span class="math inline">\(0 \leq x - \frac{a_1}{10} -
\frac{a_2}{100} &lt; \frac{1}{100}\)</span>. Continue inductively, and
then we obtain a decimal expansion <span
class="math inline">\(0.a_1a_2a_3\dots\)</span> such that <span
class="math inline">\(0 \leq x - \sum_{n=1}^k \frac{a_n}{10^n} &lt;
\frac{1}{10^k}\)</span> for any given <span
class="math inline">\(k\)</span>. By the definition of convergence, the
sequence given for <span class="math inline">\(a\)</span> tends to <span
class="math inline">\(x\)</span> as required.</p>
<p>Note, if <span class="math inline">\(0.a_1a_2\dots\)</span> and <span
class="math inline">\(0.b_1b_2\dots\)</span> are different decimal
expansions of the same number, then there exists some <span
class="math inline">\(N \in \mathbb N\)</span> such that <span
class="math inline">\(a_n = b_n\)</span> for all <span
class="math inline">\(n &lt; N\)</span> and <span
class="math inline">\(a_N = b_N - 1\)</span> and <span
class="math inline">\(a_n = 9, b_n = 0\)</span> for all <span
class="math inline">\(n &gt; N\)</span> (or vice versa). For example,
<span class="math inline">\(0.99999\dots\)</span> is equivalent to <span
class="math inline">\(1.00000\dots\)</span></p>
<h2 id="the-number-e">The number <span
class="math inline">\(e\)</span></h2>
<p>We define <span class="math display">\[e = 1 + \frac{1}{1!} +
\frac{1}{2!} + \frac{1}{3!} + \frac{1}{4!} + \dots\]</span> The partial
sums are increasing and bounded above by the powers of two after the
first term, so it converges.</p>
<h2 id="algebraic-and-transcendental-numbers">Algebraic and
transcendental numbers</h2>
<p>A real <span class="math inline">\(x\)</span> is called algebraic if
it is a root of a nonzero polynomial with integer coefficients.
Otherwise, it is called transcendental. For example, any rational <span
class="math inline">\(\frac{p}{q}\)</span> is algebraic as it is the
root of <span class="math inline">\(qx-p=0\)</span>. As another example,
<span class="math inline">\(\sqrt 2 + 1\)</span> is algebraic as it is a
root of the equation <span class="math inline">\(x^2 - 2x - 1 =
0\)</span>. The logical next question to ask is whether all reals are
algebraic.</p>
<h3>Proposition</h3>
<p><span class="math inline">\(e\)</span> is not rational.</p>
<h3>Proof</h3>
<p>Suppose that <span class="math inline">\(e\)</span> is rational, let
it be written <span class="math inline">\(\frac{p}{q}\)</span>, where
<span class="math inline">\(q &gt; 1\)</span> (if <span
class="math inline">\(q=1\)</span>, rewrite it as <span
class="math inline">\(\frac{2p}{2q}\)</span>). Multiplying up by <span
class="math inline">\(q!\)</span> (easier than just <span
class="math inline">\(q\)</span> because then we can compare factorials)
gives <span class="math display">\[\sum_{n=0}^\infty \frac{q!}{n!} \in
\mathbb Z\]</span> We know that <span class="math inline">\(\sum_{n=0}^q
\frac{q!}{n!} \in \mathbb Z\)</span>. The next terms are: <span
class="math display">\[\begin{align*}
        \frac{q!}{(q+1)!} &amp; =
\frac{1}{q+1}                                    \\
        \frac{q!}{(q+2)!} &amp; = \frac{1}{(q+1)(q+2)} \leq
\frac{1}{(q+1)^2}      \\
        \frac{q!}{(q+3)!} &amp; = \frac{1}{(q+1)(q+2)(q+3)} \leq
\frac{1}{(q+1)^3} \\
        \frac{q!}{(q+n)!} &amp; \leq
\frac{1}{(q+1)^n}                             \\
\end{align*}\]</span> So the next partial sums are bounded above by the
geometric series. <span class="math display">\[\sum_{n=q+1}^\infty
\frac{q!}{n!} \leq \frac{1}{q} &lt; 1\]</span> So the whole series
multiplied by <span class="math inline">\(q!\)</span> is a whole number
plus a fractional part, which is not an integer . ◻</p>
<p>Ideally now we’d have a proof that <span
class="math inline">\(e\)</span> is transcendental. However, even though
the terms of <span class="math inline">\(e\)</span> tend to zero
quickly, they don’t tend to zero quite quickly enough for us to be able
to prove it using what we know now. We instead prove that there exists
some transcendental number using a different example, one whose terms
tend to zero very quickly indeed.</p>
<h3>Theorem</h3>
<p>Liouville’s constant <span class="math inline">\(c =
\sum_{n=1}^\infty \frac{1}{10^{n!}}\)</span> is transcendental. As a
decimal expansion: <span class="math display">\[c =
0.1100010000000000000000010\dots\]</span></p>
<p>This is a long proof, the hardest in this course. We will cherry-pick
some important results about polynomials in order to make this proof,
without a proper introduction to features of polynomials.</p>
<ul>
<li><p>For any polynomial <span class="math inline">\(P\)</span>, <span
class="math inline">\(\exists k \in \mathbb R\)</span> such that <span
class="math inline">\(\abs{P(x) - P(y)} \leq k\abs{x-y}\)</span> for all
<span class="math inline">\(0 \leq x, y \leq 1\)</span>. Indeed, say
<span class="math inline">\(P(x) = a_d x^d + \dots + a_0\)</span>, then
<span class="math display">\[\begin{align*}
              P(x) - P(y)       &amp; = a_d(x^d - y^d) + a_{d-1}(x^{d-1}
- y^{d-1}) + \dots + a_1(x-y)     \\
                                &amp; = (x-y) [ a_d(x^{d-1} + x^{d-2}y +
\dots + y^{d-1}) + \dots + a_1 ] \\
              \abs{P(x) - P(y)} &amp; \leq \abs{x-y} [ (\abs{a_d} +
\abs{a_{d-1}} + \dots + \abs{a_1})d ]
\end{align*}\]</span> because <span class="math inline">\(x\)</span> and
<span class="math inline">\(y\)</span> are between 0 and 1.</p></li>
<li><p>A nonzero polynomial of degree <span
class="math inline">\(d\)</span> has at most <span
class="math inline">\(d\)</span> roots. Given some polynomial <span
class="math inline">\(P\)</span> of degree <span
class="math inline">\(d\)</span>:</p>
<ul>
<li><p>If <span class="math inline">\(P\)</span> has no roots, we are
trivially done.</p></li>
<li><p>If <span class="math inline">\(P\)</span> has some root <span
class="math inline">\(a\)</span>, then <span
class="math inline">\(P\)</span> can be written as <span
class="math inline">\((x-a)Q(x)\)</span>. Inductively, <span
class="math inline">\(Q(x)\)</span> has at most <span
class="math inline">\(d-1\)</span> roots, so <span
class="math inline">\(P\)</span> has at most <span
class="math inline">\(d\)</span> roots.</p></li>
</ul></li>
</ul>
<p>Now we can prove the above theorem.</p>
<h3>Proof</h3>
<p>We will write <span class="math inline">\(c_n = \sum_{k=0}^n
\frac{1}{10^{k!}}\)</span>, such that <span class="math inline">\(c_n
\to c\)</span>. Suppose that some polynomial <span
class="math inline">\(P\)</span> has <span
class="math inline">\(c\)</span> as a root. Then <span
class="math inline">\(\exists k\)</span> such that <span
class="math inline">\(\abs{P(x) - P(y)} \leq k\abs{x-y}\)</span> when
<span class="math inline">\(0 \leq x, y \leq 1\)</span>. Let <span
class="math inline">\(P\)</span> have degree <span
class="math inline">\(d\)</span>, such that <span
class="math display">\[P(x) = a_d x^d + \dots + a_0\]</span> Now, <span
class="math inline">\(\abs{c - c_n} = \sum_{k=n+1}^\infty
\frac{1}{10^{k!}} \leq \frac{2}{10^{(n+1)!}}\)</span>. This is a trivial
upper bound, of course better upper bounds exist.</p>
<p>Also, <span class="math inline">\(c_n = \frac{a}{10^{n!}}\)</span>
for some <span class="math inline">\(a \in \mathbb Z\)</span>. So <span
class="math inline">\(P(c_n) = \frac{b}{10^{dn!}}\)</span> for some
<span class="math inline">\(b \in \mathbb Z\)</span> (since <span
class="math inline">\(P(\frac{s}{t}) = \frac{q}{t^d}\)</span> for some
integer <span class="math inline">\(q\)</span>, where <span
class="math inline">\(\frac{s}{t} \in \mathbb Q\)</span>).</p>
<p>For <span class="math inline">\(n\)</span> large enough, <span
class="math inline">\(c_n\)</span> is not a root, because <span
class="math inline">\(P\)</span> only has finitely many roots. So <span
class="math display">\[\abs{P(c) - P(c_n)} = \abs{P(c_n)} \leq
\frac{1}{10^{dn!}}\]</span> Therefore <span
class="math display">\[\frac{1}{10^{dn!}} \leq
k\frac{2}{10^{(n+1)!}}\]</span> which is a contradiction if <span
class="math inline">\(n\)</span> is large enough. ◻</p>
<p>Here are some remarks about this proof.</p>
<ul>
<li><p>This same proof shows that any real <span
class="math inline">\(x\)</span> such that <span
class="math inline">\(\forall n \exists \frac{p}{q}\in \mathbb
Q\)</span> with <span class="math inline">\(0 &lt; \abs{x - \frac{p}{q}}
&lt; \frac{1}{q^n}\)</span> is transcendental. Informally, <span
class="math inline">\(x\)</span> has very good rational
approximations.</p></li>
<li><p>Such <span class="math inline">\(x\)</span> are often called
Liouville numbers; the proof works for all Liouville numbers.</p></li>
<li><p>This proof does not show that <span
class="math inline">\(e\)</span> is transcendental (even though it is),
because the terms do not go to zero fast enough.</p></li>
<li><p>We now know that there exist some transcendental numbers. Another
proof of existence of transcendental numbers will be seen in a later
lecture.</p></li>
</ul>
<h2 id="complex-numbers">Complex numbers</h2>
<p>Some polynomials have no real roots, for example <span
class="math inline">\(x^2 + 1\)</span>. We’ll try to ‘force’ an <span
class="math inline">\(x\)</span> with the property <span
class="math inline">\(x^2 = -1\)</span>. Note that for example we could
not force an <span class="math inline">\(x\)</span> into existence with
the property <span class="math inline">\(x^2=2, x^3=3\)</span>; how do
we know introducing <span class="math inline">\(i\)</span> will not lead
to a contradiction? We will define <span class="math inline">\(\mathbb
C\)</span> to consist of the plane <span class="math inline">\(\mathbb
R^2\)</span>, i.e. pairs of real numbers, with operations <span
class="math inline">\(+\)</span> and <span
class="math inline">\(\cdot\)</span> which satisfy:</p>
<ul>
<li><p><span class="math inline">\((a,b)+(c,d) = (a+c,
b+d)\)</span></p></li>
<li><p><span class="math inline">\((a,b)\cdot(c,d) = (ac-bd,
ad+bc)\)</span></p></li>
</ul>
<p>We can view <span class="math inline">\(\mathbb R\)</span> as being
contained within <span class="math inline">\(\mathbb C\)</span> by
identifying the real number <span class="math inline">\(a\)</span> with
<span class="math inline">\((a, 0)\)</span>. Note that the rules of
arithmetic of the reals are inherited inside the first element of the
complex plane, so there is no contradiction here. Then let <span
class="math inline">\(i=(0,1)\)</span>. Trivially then, any point <span
class="math inline">\((a, b)\)</span> in the complex numbers may be
written as <span class="math inline">\(a+bi\)</span> where <span
class="math inline">\(a, b \in \mathbb R\)</span>. And, of course, <span
class="math inline">\(i^2 = -1\)</span>.</p>
<p>All of the basic rules like associativity and distributivity work in
the complex plane. There are multiplicative inverses: given <span
class="math inline">\(a+bi\)</span>, we know that <span
class="math inline">\((a+bi)(a-bi) = a^2 + b^2\)</span> so <span
class="math inline">\(\frac{a-bi}{a^2 + b^2}\)</span> is the inverse
(provided the point is nonzero). This kind of structure with familiar
properties is known as a field, for example <span
class="math inline">\(\mathbb C\)</span>, <span
class="math inline">\(\mathbb R\)</span>, <span
class="math inline">\(\mathbb Q\)</span>, <span
class="math inline">\(\mathbb Z_p\)</span> where <span
class="math inline">\(p\)</span> is prime. The fundamental theorem of
algebra states that any nonzero polynomial with complex coefficients has
a complex root; this is proven in the IB course Complex Analysis.</p>
</main>

<footer>
  <p><a href="../../">Main Homepage</a></p>
</footer>

</body>
</html>
